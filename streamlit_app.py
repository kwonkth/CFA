import io
import os
from datetime import datetime
from typing import List, Optional, Tuple

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer


# -----------------------------
# Utilities
# -----------------------------

KOREAN_BASIC_STOPWORDS: List[str] = [
    "ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì—", "ì—ì„œ", "ì˜", "ì™€", "ê³¼", "ë„", "ìœ¼ë¡œ",
    "í•˜ê³ ", "í•œ", "í•˜ë‹¤", "í–ˆìŠµë‹ˆë‹¤", "í•©ë‹ˆë‹¤", "ê·¸ë¦¬ê³ ", "í•˜ì§€ë§Œ", "ê·¸ë˜ì„œ", "ê·¸ëŸ¬ë‚˜",
    "í˜¹ì€", "ë˜ëŠ”", "ë•Œë¬¸", "ë•Œë¬¸ì—", "ëŒ€í•œ", "ê´€ë ¨", "í•©ë‹ˆë‹¤.", "ì…ë‹ˆë‹¤", "ìˆì–´ìš”",
]


def split_text_to_tokens(text: str) -> List[str]:
    if not isinstance(text, str):
        return []
    import re

    tokens = re.findall(r"[ê°€-í£a-zA-Z0-9]+", text.lower())
    tokens = [t for t in tokens if t not in KOREAN_BASIC_STOPWORDS and len(t) > 1]
    return tokens


def label_sentiment(compound_score: float) -> str:
    if compound_score >= 0.05:
        return "ê¸ì •"
    if compound_score <= -0.05:
        return "ë¶€ì •"
    return "ì¤‘ë¦½"


@st.cache_data(show_spinner=False)
def read_local_csv_if_exists(path: str) -> Optional[pd.DataFrame]:
    if os.path.exists(path) and os.path.isfile(path):
        try:
            return pd.read_csv(path)
        except Exception:
            return None
    return None


def parse_date_column(df: pd.DataFrame, column_name: str) -> pd.Series:
    series = pd.to_datetime(df[column_name], errors="coerce")
    return series


@st.cache_data(show_spinner=False)
def run_sentiment_analysis(texts: List[str]) -> Tuple[np.ndarray, List[str]]:
    analyzer = SentimentIntensityAnalyzer()
    scores = np.array([analyzer.polarity_scores(t or "").get("compound", 0.0) for t in texts])
    labels = [label_sentiment(s) for s in scores]
    return scores, labels


@st.cache_data(show_spinner=False)
def extract_top_keywords(texts: List[str], top_k: int = 20) -> pd.DataFrame:
    if len(texts) == 0:
        return pd.DataFrame({"keyword": [], "score": []})

    vectorizer = TfidfVectorizer(
        tokenizer=split_text_to_tokens,
        preprocessor=lambda x: x,
        token_pattern=None,
        ngram_range=(1, 2),
        min_df=2,
        max_features=5000,
    )
    try:
        tfidf = vectorizer.fit_transform(texts)
    except ValueError:
        return pd.DataFrame({"keyword": [], "score": []})

    scores = np.asarray(tfidf.sum(axis=0)).ravel()
    terms = np.array(vectorizer.get_feature_names_out())

    order = np.argsort(scores)[::-1][:top_k]
    return pd.DataFrame({"keyword": terms[order], "score": scores[order]})


def filter_dataframe(
    df: pd.DataFrame,
    date_column: Optional[str],
    category_column: Optional[str],
    date_range: Optional[Tuple[datetime, datetime]],
    categories_selected: Optional[List[str]],
) -> pd.DataFrame:
    filtered = df.copy()

    if date_column and date_range is not None:
        parsed = parse_date_column(filtered, date_column)
        start, end = date_range
        mask = (parsed >= pd.Timestamp(start)) & (parsed <= pd.Timestamp(end))
        filtered = filtered[mask]

    if category_column and categories_selected:
        filtered = filtered[filtered[category_column].isin(categories_selected)]

    return filtered


def ensure_text_column(df: pd.DataFrame) -> Optional[str]:
    candidate_names = [
        "text", "feedback", "review", "comment", "content", "message", "summary",
        "í…ìŠ¤íŠ¸", "í”¼ë“œë°±", "ë¦¬ë·°", "ì½”ë©˜íŠ¸", "ë‚´ìš©", "ë©”ì‹œì§€",
    ]
    for name in candidate_names:
        if name in df.columns:
            return name
    # fallback: longest object column
    object_cols = [c for c in df.columns if df[c].dtype == "object"]
    return object_cols[0] if object_cols else None


def main() -> None:
    st.set_page_config(page_title="ê³ ê° í”¼ë“œë°± ë¶„ì„", page_icon="ğŸ§ ", layout="wide")
    st.title("ê³ ê° í”¼ë“œë°± ë¶„ì„ (Streamlit)")
    st.caption("CSV ë˜ëŠ” Excelì„ ì—…ë¡œë“œí•˜ê³  ê°ì„± ë¶„ì„ê³¼ í‚¤ì›Œë“œ ì¶”ì¶œì„ ì‹¤í–‰í•˜ì„¸ìš”.")

    with st.sidebar:
        st.header("ë°ì´í„° ì—…ë¡œë“œ")
        uploaded = st.file_uploader(
            "í”¼ë“œë°± ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ (CSV ë˜ëŠ” Excel)", type=["csv", "xlsx", "xls"]
        )
        st.markdown("---")
        st.caption("ë¡œì»¬ì˜ '@feedback-data.csv' ìë™ íƒì§€ ì‹œ ê¸°ë³¸ ë¡œë“œ")

    df: Optional[pd.DataFrame] = None
    if uploaded is not None:
        try:
            if uploaded.name.lower().endswith(".csv"):
                df = pd.read_csv(uploaded)
            else:
                import openpyxl  # noqa: F401  # ensure dependency
                df = pd.read_excel(uploaded)
        except Exception as e:
            st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    else:
        df = read_local_csv_if_exists(os.path.join(os.getcwd(), "@feedback-data.csv"))

    if df is None or df.empty:
        st.info(
            "ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”. ì˜ˆ: '@feedback-data.csv' ë˜ëŠ” Excel íŒŒì¼. "
            "í…ìŠ¤íŠ¸ ì»¬ëŸ¼ 1ê°œ ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤."
        )
        return

    st.subheader("ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(df.head(200), use_container_width=True)

    with st.sidebar:
        st.header("ì»¬ëŸ¼ ë§¤í•‘ ë° í•„í„°")
        text_column_default = ensure_text_column(df)
        text_column = st.selectbox(
            "í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì„ íƒ",
            options=list(df.columns),
            index=list(df.columns).index(text_column_default) if text_column_default in df.columns else 0,
        )

        possible_date_cols = [c for c in df.columns if "date" in c.lower() or "ë‚ ì§œ" in c]
        date_column = st.selectbox(
            "ë‚ ì§œ ì»¬ëŸ¼(ì„ íƒ)", options=["(ì—†ìŒ)"] + list(df.columns), index=0
        )
        date_column = None if date_column == "(ì—†ìŒ)" else date_column

        category_column = st.selectbox(
            "ì¹´í…Œê³ ë¦¬/ì œí’ˆ ì»¬ëŸ¼(ì„ íƒ)", options=["(ì—†ìŒ)"] + list(df.columns), index=0
        )
        category_column = None if category_column == "(ì—†ìŒ)" else category_column

        date_range: Optional[Tuple[datetime, datetime]] = None
        if date_column:
            date_series = parse_date_column(df, date_column)
            min_date = pd.to_datetime(date_series.min())
            max_date = pd.to_datetime(date_series.max())
            if pd.isna(min_date) or pd.isna(max_date):
                st.warning("ì„ íƒí•œ ë‚ ì§œ ì»¬ëŸ¼ì— ìœ íš¨í•œ ê°’ì´ ì ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            else:
                date_range = st.date_input(
                    "ê¸°ê°„ í•„í„°",
                    value=(min_date.to_pydatetime(), max_date.to_pydatetime()),
                )
                if isinstance(date_range, tuple) and len(date_range) == 2:
                    date_range = (date_range[0], date_range[1])
                else:
                    date_range = None

        categories_selected: Optional[List[str]] = None
        if category_column:
            all_categories = sorted(list(map(str, df[category_column].dropna().unique())))
            categories_selected = st.multiselect("ì¹´í…Œê³ ë¦¬ ì„ íƒ", options=all_categories)

        st.markdown("---")
        top_k = st.slider("ìƒìœ„ í‚¤ì›Œë“œ ê°œìˆ˜", min_value=10, max_value=50, value=20, step=5)
        run_button = st.button("ë¶„ì„ ì‹¤í–‰", type="primary")

    if not run_button:
        st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ì˜µì…˜ì„ ì„¤ì •í•˜ê³  'ë¶„ì„ ì‹¤í–‰'ì„ í´ë¦­í•˜ì„¸ìš”.")
        return

    working_df = filter_dataframe(df, date_column, category_column, date_range, categories_selected)
    if working_df.empty:
        st.warning("í•„í„° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì¡°ê±´ì„ ì™„í™”í•´ ë³´ì„¸ìš”.")
        return

    texts = working_df[text_column].fillna("").astype(str).tolist()

    with st.spinner("ê°ì„± ë¶„ì„ ì¤‘..."):
        compound_scores, labels = run_sentiment_analysis(texts)

    working_df = working_df.copy()
    working_df["sentiment_score"] = compound_scores
    working_df["sentiment_label"] = labels

    st.subheader("ê°ì„± ë¶„í¬")
    label_counts = (
        working_df["sentiment_label"].value_counts().rename_axis("label").reset_index(name="count")
    )
    fig_bar = px.bar(
        label_counts,
        x="label",
        y="count",
        color="label",
        text="count",
        color_discrete_map={"ê¸ì •": "#2ca02c", "ì¤‘ë¦½": "#ff7f0e", "ë¶€ì •": "#d62728"},
        title="ê°ì„± ë¼ë²¨ ë¶„í¬",
    )
    fig_bar.update_layout(xaxis_title="ë¼ë²¨", yaxis_title="ê°œìˆ˜")
    st.plotly_chart(fig_bar, use_container_width=True)

    st.subheader("ìƒìœ„ í‚¤ì›Œë“œ")
    with st.spinner("í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘..."):
        keyword_df = extract_top_keywords(texts, top_k=top_k)
    if keyword_df.empty:
        st.info("í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ ë„ˆë¬´ ì ê±°ë‚˜ ì¼ì¹˜ í† í°ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    else:
        fig_kw = px.bar(
            keyword_df.iloc[::-1],
            x="score",
            y="keyword",
            orientation="h",
            title="TF-IDF ê¸°ë°˜ ìƒìœ„ í‚¤ì›Œë“œ",
        )
        fig_kw.update_layout(xaxis_title="ì ìˆ˜", yaxis_title="í‚¤ì›Œë“œ")
        st.plotly_chart(fig_kw, use_container_width=True)

    with st.expander("ë¶„ì„ ê²°ê³¼ ë°ì´í„°"):
        st.dataframe(working_df.head(1000), use_container_width=True)
        csv = working_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="feedback_analysis_result.csv", mime="text/csv")

    st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()



